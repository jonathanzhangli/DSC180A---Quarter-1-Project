{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import json\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge(adj_list, node, target):\n",
    "    adj_list[int(node)].append(int(target)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adj_list(data):\n",
    "    #initialize adjacency lists\n",
    "    min_node = data['FromNodeId'].min()\n",
    "    max_node = data['FromNodeId'].max()\n",
    "\n",
    "    adj_list_away = {}\n",
    "    adj_list_toward = {}\n",
    "\n",
    "    for node in range(min_node, max_node+1):\n",
    "        adj_list_away[node] = []\n",
    "        adj_list_toward[node] = []\n",
    "        \n",
    "    for idx, row in data.iterrows():\n",
    "        add_edge(adj_list_away, row.FromNodeId, row.ToNodeId)\n",
    "        add_edge(adj_list_toward, row.ToNodeId, row.FromNodeId)\n",
    "        \n",
    "    return adj_list_away, adj_list_toward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City Reachability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = pd.read_csv('City Reachability/reachability.txt', header = 5, delimiter = ' ')\n",
    "\n",
    "#fix column names\n",
    "city = city.rename(columns = {'#': 'FromNodeId', 'FromNodeId': 'ToNodeId', 'ToNodeId': 'Weight', 'Weight': 'redundant'})\n",
    "city = city[city.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(456,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([city['ToNodeId'], city['FromNodeId']]).unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromNodeId</th>\n",
       "      <th>ToNodeId</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>-757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>-84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>-1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>-465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71954</th>\n",
       "      <td>419</td>\n",
       "      <td>455</td>\n",
       "      <td>-154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71955</th>\n",
       "      <td>428</td>\n",
       "      <td>455</td>\n",
       "      <td>-341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71956</th>\n",
       "      <td>434</td>\n",
       "      <td>455</td>\n",
       "      <td>-403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71957</th>\n",
       "      <td>440</td>\n",
       "      <td>455</td>\n",
       "      <td>-680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71958</th>\n",
       "      <td>444</td>\n",
       "      <td>455</td>\n",
       "      <td>-265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71959 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FromNodeId  ToNodeId  Weight\n",
       "0              27         0    -757\n",
       "1              57         0     -84\n",
       "2              70         0   -1290\n",
       "3              74         0    -465\n",
       "4              86         0    -700\n",
       "...           ...       ...     ...\n",
       "71954         419       455    -154\n",
       "71955         428       455    -341\n",
       "71956         434       455    -403\n",
       "71957         440       455    -680\n",
       "71958         444       455    -265\n",
       "\n",
       "[71959 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjacency list away consists of edges going AWAY a certain node\n",
    "#adjacency list toward consists of edges going TOWARD a certain node\n",
    "city_adj_list_away, city_adj_list_toward = create_adj_list(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_all_nodes = pd.concat([city['FromNodeId'], city['ToNodeId']]).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford = pd.read_csv('Stanford Web/web-Stanford.txt', header = 3, delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromNodeId</th>\n",
       "      <th>ToNodeId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6548</td>\n",
       "      <td>57031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15409</td>\n",
       "      <td>13102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>17794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312492</th>\n",
       "      <td>281865</td>\n",
       "      <td>186750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312493</th>\n",
       "      <td>281865</td>\n",
       "      <td>225872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312494</th>\n",
       "      <td>281888</td>\n",
       "      <td>114388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312495</th>\n",
       "      <td>281888</td>\n",
       "      <td>192969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312496</th>\n",
       "      <td>281888</td>\n",
       "      <td>233184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2312497 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FromNodeId  ToNodeId\n",
       "0                 1      6548\n",
       "1                 1     15409\n",
       "2              6548     57031\n",
       "3             15409     13102\n",
       "4                 2     17794\n",
       "...             ...       ...\n",
       "2312492      281865    186750\n",
       "2312493      281865    225872\n",
       "2312494      281888    114388\n",
       "2312495      281888    192969\n",
       "2312496      281888    233184\n",
       "\n",
       "[2312497 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating adj lists takes a while, avoid running if possible\n",
    "\n",
    "#stanford_adj_list_away, stanford_adj_list_toward = create_adj_list(stanford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saved the adj lists for future use\n",
    "\n",
    "with open('Stanford Web/adj_list_away.json', 'r') as fp:\n",
    "    stanford_adj_list_away = json.load(fp)\n",
    "    \n",
    "with open('Stanford Web/adj_list_toward.json', 'r') as fp:\n",
    "    stanford_adj_list_toward = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_all_nodes = pd.concat([stanford['FromNodeId'], stanford['ToNodeId']]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define counting functions (naive method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M1(adj_list_away, adj_list_toward):\n",
    "\n",
    "    vertices = [] #store vertices\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            for vertex3 in adj_list_away[vertex2]:\n",
    "                \n",
    "                if ((vertex1 in adj_list_away[vertex3]) & (vertex1 not in adj_list_toward[vertex3])\n",
    "                    & (vertex3 not in adj_list_toward[vertex2]) & (vertex2 not in adj_list_toward[vertex1])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    #return triangles\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M2(adj_list_away, adj_list_toward):\n",
    "\n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            for vertex3 in adj_list_away[vertex2]: #access all possible nodes (vertex 3) from vertex 2\n",
    "                \n",
    "                if ((vertex1 in adj_list_away[vertex3]) & (vertex1 not in adj_list_toward[vertex3])\n",
    "                    & (vertex3 not in adj_list_toward[vertex2]) & (vertex2 in adj_list_toward[vertex1])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M3(adj_list_away, adj_list_toward):\n",
    "\n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            for vertex3 in adj_list_away[vertex2]: #access all possible nodes (vertex 3) from vertex 2\n",
    "                \n",
    "                if ((vertex1 in adj_list_away[vertex3]) & (vertex1 not in adj_list_toward[vertex3])\n",
    "                    & (vertex3 in adj_list_toward[vertex2]) & (vertex2 in adj_list_toward[vertex1])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M4(adj_list_away, adj_list_toward):\n",
    "\n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            for vertex3 in adj_list_away[vertex2]: #access all possible nodes (vertex 3) from vertex 2\n",
    "                \n",
    "                if ((vertex1 in adj_list_away[vertex3]) & (vertex1 in adj_list_toward[vertex3])\n",
    "                    & (vertex3 in adj_list_toward[vertex2]) & (vertex2 in adj_list_toward[vertex1])\n",
    "                    & (vertex1 != vertex2) & (vertex1 != vertex3) & (vertex2 != vertex3)):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M5(adj_list_away, adj_list_toward):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each parent node\n",
    "        for vertex2 in adj_list_away[vertex1]: #checks first child node\n",
    "            for vertex3 in adj_list_away[vertex1]:\n",
    "                \n",
    "                if ((vertex3 in adj_list_away[vertex2]) & (vertex3 not in adj_list_toward[vertex2])\n",
    "                    & (vertex2 not in adj_list_toward[vertex1]) & (vertex3 not in adj_list_toward[vertex1])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M6(adj_list_away, adj_list_toward):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each parent node\n",
    "        for vertex2 in adj_list_away[vertex1]: #checks first child node\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in adj_list_away[vertex1]:\n",
    "                \n",
    "                if ((vertex3 in adj_list_away[vertex2]) & (vertex3 in adj_list_toward[vertex2])\n",
    "                    & (vertex2 not in adj_list_toward[vertex1]) & (vertex3 not in adj_list_toward[vertex1])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M7(adj_list_away, adj_list_toward):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each parent node\n",
    "        for vertex2 in adj_list_toward[vertex1]: #checks first child node\n",
    "            for vertex3 in adj_list_toward[vertex1]: #checks second child node\n",
    "                \n",
    "                if ((vertex2 not in adj_list_away[vertex1]) & (vertex3 not in adj_list_away[vertex1])\n",
    "                   & (vertex2 in adj_list_away[vertex3]) & (vertex3 in adj_list_away[vertex2])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M8(adj_list_away, adj_list_toward):\n",
    "\n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each vertex1 node\n",
    "        for vertex2 in adj_list_away[vertex1]: #checks first child node\n",
    "            for vertex3 in adj_list_away[vertex1]: \n",
    "\n",
    "                if ((vertex3 not in adj_list_away[vertex2]) & (vertex3 not in adj_list_toward[vertex2])\n",
    "                    & (vertex2 not in adj_list_toward[vertex1]) & (vertex3 not in adj_list_toward[vertex1])\n",
    "                    & (vertex2 != vertex3)):\n",
    "\n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "\n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "\n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "\n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else: #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "\n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M9(adj_list_away, adj_list_toward):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            for vertex3 in adj_list_away[vertex2]: #access all possible nodes (vertex 3) from vertex 2\n",
    "                \n",
    "                if ((vertex1 not in adj_list_away[vertex3]) & (vertex1 not in adj_list_toward[vertex3])\n",
    "                    & (vertex3 not in adj_list_toward[vertex2]) & (vertex2 not in adj_list_toward[vertex1])\n",
    "                    & (vertex1 != vertex3)):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M10(adj_list_away, adj_list_toward):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks first vertex\n",
    "        for vertex2 in adj_list_toward[vertex1]: #checks second vertex\n",
    "            for vertex3 in adj_list_toward[vertex1]:\n",
    "                \n",
    "                if ((vertex2 not in adj_list_away[vertex1]) & (vertex3 not in adj_list_away[vertex1])\n",
    "                    & (vertex2 not in adj_list_away[vertex3]) & (vertex3 not in adj_list_away[vertex2])\n",
    "                    & (vertex2 != vertex3)):\n",
    "\n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M11(adj_list_away, adj_list_toward):\n",
    "\n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each vertex1 node\n",
    "        for vertex2 in adj_list_away[vertex1]: #checks first child node\n",
    "            for vertex3 in adj_list_away[vertex1]:\n",
    "\n",
    "                if ((vertex3 not in adj_list_away[vertex2]) & (vertex3 not in adj_list_toward[vertex2])\n",
    "                    & (vertex2 in adj_list_toward[vertex1]) & (vertex3 not in adj_list_toward[vertex1])\n",
    "                    & (vertex2 != vertex3)):\n",
    "\n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "\n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "\n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "\n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else: #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "\n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M12(adj_list_away, adj_list_toward):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            for vertex3 in adj_list_away[vertex2]:\n",
    "                \n",
    "                if ((vertex1 not in adj_list_away[vertex3]) & (vertex1 not in adj_list_toward[vertex3])\n",
    "                    & (vertex3 in adj_list_toward[vertex2]) & (vertex2 not in adj_list_toward[vertex1])\n",
    "                    & (vertex1 != vertex3)):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLD_count_M13(adj_list_away, adj_list_toward):\n",
    "\n",
    "    vertices = []\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each vertex1 node\n",
    "        for vertex2 in adj_list_away[vertex1]: #checks first child node\n",
    "            for vertex3 in adj_list_away[vertex1]:\n",
    "\n",
    "                if ((vertex3 not in adj_list_away[vertex2]) & (vertex3 not in adj_list_toward[vertex2])\n",
    "                    & (vertex2 in adj_list_toward[vertex1]) & (vertex3 in adj_list_toward[vertex1])\n",
    "                    & (vertex2 != vertex3)):\n",
    "\n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "\n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "\n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "\n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else: #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "\n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define counting functions (sampling method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M1(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "\n",
    "    vertices = [] #store vertices\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            for vertex3 in sampled_nodes:\n",
    "                \n",
    "                if ((vertex1 in adj_list_away[vertex3]) & (vertex1 not in adj_list_toward[vertex3])\n",
    "                    & (vertex3 not in adj_list_toward[vertex2]) & (vertex2 not in adj_list_toward[vertex1])\n",
    "                    & (vertex3 in adj_list_away[vertex2])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    #return triangles\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M2(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "\n",
    "    vertices = [] #store vertices\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes:\n",
    "                \n",
    "                if ((vertex1 in adj_list_away[vertex3]) & (vertex1 not in adj_list_toward[vertex3])\n",
    "                    & (vertex3 not in adj_list_toward[vertex2]) & (vertex2 in adj_list_toward[vertex1])\n",
    "                    & (vertex3 in adj_list_away[vertex2])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M3(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "\n",
    "    vertices = [] #store vertices\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes:\n",
    "                \n",
    "                if ((vertex1 in adj_list_away[vertex3]) & (vertex1 not in adj_list_toward[vertex3])\n",
    "                    & (vertex3 in adj_list_toward[vertex2]) & (vertex2 in adj_list_toward[vertex1])\n",
    "                    & (vertex3 in adj_list_away[vertex2])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M4(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "\n",
    "    vertices = []\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes:\n",
    "                \n",
    "                if ((vertex1 in adj_list_away[vertex3]) & (vertex1 in adj_list_toward[vertex3])\n",
    "                    & (vertex3 in adj_list_toward[vertex2]) & (vertex2 in adj_list_toward[vertex1])\n",
    "                    & (vertex1 != vertex2) & (vertex1 != vertex3) & (vertex2 != vertex3)\n",
    "                    & (vertex3 in adj_list_away[vertex2])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M5(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each parent node\n",
    "        for vertex2 in adj_list_away[vertex1]: #checks first child node\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes:\n",
    "                \n",
    "                if ((vertex3 in adj_list_away[vertex2]) & (vertex3 not in adj_list_toward[vertex2])\n",
    "                    & (vertex2 not in adj_list_toward[vertex1]) & (vertex3 not in adj_list_toward[vertex1])\n",
    "                    & (vertex3 in adj_list_away[vertex1])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M6(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each parent node\n",
    "        for vertex2 in adj_list_away[vertex1]: #checks first child node\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes:\n",
    "                \n",
    "                if ((vertex3 in adj_list_away[vertex2]) & (vertex3 in adj_list_toward[vertex2])\n",
    "                    & (vertex2 not in adj_list_toward[vertex1]) & (vertex3 not in adj_list_toward[vertex1])\n",
    "                    & (vertex3 in adj_list_away[vertex1])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M7(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each parent node\n",
    "        for vertex2 in adj_list_toward[vertex1]: #checks first child node\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes:  \n",
    "                \n",
    "                if ((vertex2 not in adj_list_away[vertex1]) & (vertex3 not in adj_list_away[vertex1])\n",
    "                   & (vertex2 in adj_list_away[vertex3]) & (vertex3 in adj_list_away[vertex2])\n",
    "                   & (vertex3 in adj_list_toward[vertex1])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M8(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "\n",
    "    vertices = []\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each vertex1 node\n",
    "        for vertex2 in adj_list_away[vertex1]: #checks first child node\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes: \n",
    "\n",
    "                if ((vertex3 not in adj_list_away[vertex2]) & (vertex3 not in adj_list_toward[vertex2])\n",
    "                    & (vertex2 not in adj_list_toward[vertex1]) & (vertex3 not in adj_list_toward[vertex1])\n",
    "                    & (vertex2 != vertex3) & (vertex3 in adj_list_away[vertex1])):\n",
    "\n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "\n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "\n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "\n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else: #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "\n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M9(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes: \n",
    "                \n",
    "                if ((vertex1 not in adj_list_away[vertex3]) & (vertex1 not in adj_list_toward[vertex3])\n",
    "                    & (vertex3 not in adj_list_toward[vertex2]) & (vertex2 not in adj_list_toward[vertex1])\n",
    "                    & (vertex1 != vertex3) & (vertex3 in adj_list_away[vertex2])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M10(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks first vertex\n",
    "        for vertex2 in adj_list_toward[vertex1]: #checks second vertex\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes:\n",
    "                \n",
    "                if ((vertex2 not in adj_list_away[vertex1]) & (vertex3 not in adj_list_away[vertex1])\n",
    "                    & (vertex2 not in adj_list_away[vertex3]) & (vertex3 not in adj_list_away[vertex2])\n",
    "                    & (vertex2 != vertex3) & (vertex3 in adj_list_toward[vertex1])):\n",
    "\n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M11(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "\n",
    "    vertices = []\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each vertex1 node\n",
    "        for vertex2 in adj_list_away[vertex1]: #checks first child node\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes:\n",
    "\n",
    "                if ((vertex3 not in adj_list_away[vertex2]) & (vertex3 not in adj_list_toward[vertex2])\n",
    "                    & (vertex2 in adj_list_toward[vertex1]) & (vertex3 not in adj_list_toward[vertex1])\n",
    "                    & (vertex2 != vertex3) & (vertex3 in adj_list_away[vertex1])):\n",
    "\n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "\n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "\n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "\n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else: #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "\n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M12(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each starting vertex\n",
    "        for vertex2 in adj_list_away[vertex1]: #access all possible nodes (vertex 2) from vertex 1\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes:\n",
    "                \n",
    "                if ((vertex1 not in adj_list_away[vertex3]) & (vertex1 not in adj_list_toward[vertex3])\n",
    "                    & (vertex3 in adj_list_toward[vertex2]) & (vertex2 not in adj_list_toward[vertex1])\n",
    "                    & (vertex1 != vertex3) & (vertex3 in adj_list_away[vertex2])):\n",
    "                    \n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "                    \n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "        \n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else:                            #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "    \n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_M13(all_nodes, adj_list_away, adj_list_toward, num_sample):\n",
    "\n",
    "    vertices = []\n",
    "    \n",
    "    #randomly sample third vertices at uniform from all possible nodes\n",
    "    sampled_nodes = np.random.choice(all_nodes, num_sample)\n",
    "    \n",
    "    for vertex1 in adj_list_away: #checks each vertex1 node\n",
    "        for vertex2 in adj_list_away[vertex1]: #checks first child node\n",
    "            \n",
    "            #randomly sample a third vertex at uniform from all possible nodes\n",
    "            for vertex3 in sampled_nodes:\n",
    "\n",
    "                if ((vertex3 not in adj_list_away[vertex2]) & (vertex3 not in adj_list_toward[vertex2])\n",
    "                    & (vertex2 in adj_list_toward[vertex1]) & (vertex3 in adj_list_toward[vertex1])\n",
    "                    & (vertex2 != vertex3) & (vertex3 in adj_list_away[vertex1])):\n",
    "\n",
    "                    vertices.append([vertex1, vertex2, vertex3])\n",
    "\n",
    "    triangles = set(tuple(sorted(l)) for l in vertices) #get rid of permutations of the same triangle\n",
    "\n",
    "    edge_dict = {}\n",
    "    for tri in triangles:\n",
    "\n",
    "        combos = list(itertools.combinations(tri, 2))\n",
    "\n",
    "        for edge in combos:\n",
    "\n",
    "            if edge not in edge_dict.keys(): #if edge doesn't exist yet\n",
    "                edge_dict[edge] = 1\n",
    "            else: #if edge does exist\n",
    "                edge_dict[edge] += 1 #add to edge count\n",
    "\n",
    "    return len(triangles), edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get motif counts (city reachability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M1_count, OLD_edge_dict_M1 = OLD_count_M1(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_count, edge_dict_M1 = count_M1(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M2_count, OLD_edge_dict_M2 = OLD_count_M2(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13999"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2_count, edge_dict_M2 = count_M2(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M3_count, OLD_edge_dict_M3 = OLD_count_M3(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270284"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M3_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_count, edge_dict_M3 = count_M3(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1931"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M3_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M4_count, OLD_edge_dict_M4 = OLD_count_M4(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1497244"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M4_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "M4_count, edge_dict_M4 = count_M4(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65497"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M4_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M5_count, OLD_edge_dict_M5 = OLD_count_M5(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1182"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M5_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "M5_count, edge_dict_M5 = count_M5(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M5_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M6_count, OLD_edge_dict_M6 = OLD_count_M6(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15111"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M6_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "M6_count, edge_dict_M6 = count_M6(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M6_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M7_count, OLD_edge_dict_M7 = OLD_count_M7(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16393"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M7_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "M7_count, edge_dict_M7 = count_M7(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M7_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M8_count, OLD_edge_dict_M8 = OLD_count_M8(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16013"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M8_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "M8_count, edge_dict_M8 = count_M8(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M8_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M9_count, OLD_edge_dict_M9 = OLD_count_M9(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25124"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M9_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "M9_count, edge_dict_M9 = count_M9(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M9_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M10_count, OLD_edge_dict_M10 = OLD_count_M10(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15280"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M10_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "M10_count, edge_dict_M10 = count_M10(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M10_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M11_count, OLD_edge_dict_M11 = OLD_count_M11(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349821"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M11_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "M11_count, edge_dict_M11 = count_M11(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5142"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M11_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M12_count, OLD_edge_dict_M12 = OLD_count_M12(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338073"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M12_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "M12_count, edge_dict_M12 = count_M12(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3086"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M12_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M13_count, OLD_edge_dict_M13 = OLD_count_M13(city_adj_list_away, city_adj_list_toward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2840251"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M13_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "M13_count, edge_dict_M13 = count_M13(city_all_nodes, city_adj_list_away, city_adj_list_toward, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73478"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M13_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the motif adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_motif_adjacency_matrix(edge_dict):\n",
    "    \n",
    "    #get all unique nodes\n",
    "    first_half = [x[0] for x in edge_dict.keys()]\n",
    "    second_half = [x[1] for x in edge_dict.keys()]\n",
    "    combined = np.concatenate((first_half, second_half))\n",
    "    \n",
    "    unique_nodes = np.unique(combined)\n",
    "    \n",
    "    #define an empty dataframe to use as the motif adjacency matrix\n",
    "    motif_adjacency_matrix = pd.DataFrame(index = unique_nodes, columns = unique_nodes)\n",
    "    \n",
    "    #populate motif adjacency matrix\n",
    "    for key, value in edge_dict.items():\n",
    "        motif_adjacency_matrix[key[0]][key[1]] = value\n",
    "        motif_adjacency_matrix[key[1]][key[0]] = value\n",
    "\n",
    "    motif_adjacency_matrix = motif_adjacency_matrix.fillna(0)\n",
    "    \n",
    "    return motif_adjacency_matrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_M10_matrix = create_motif_adjacency_matrix(OLD_edge_dict_M10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the single most optimal cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_cluster(adj_matrix):\n",
    "    '''\n",
    "    Input: motif adjacency matrix (W)\n",
    "    Output:\n",
    "    '''\n",
    "    # Step 1: Form the Diagonal Matrix (D) from W\n",
    "    # -----------------------------------------\n",
    "    # obtain the sums of all the rows of W\n",
    "    row_sums = np.sum(adj_matrix, axis = 1)\n",
    "    \n",
    "    # calculate D (to the -1/2 power) utilizing the row sums\n",
    "    D = np.diag(row_sums**(-1/2))\n",
    "    \n",
    "    # Step 2: Calculate the normalized Laplacian matrix (L)\n",
    "    # -----------------------------------------\n",
    "    L = np.identity(len(row_sums)) - D@adj_matrix@D\n",
    "\n",
    "    # Step 3: Calculate the eigenvector corrsponding to the second smallest eigenvalue of L\n",
    "    # -----------------------------------------\n",
    "    # calculate the eigenvalues and eigenvectors \n",
    "    eig = np.linalg.eig(L)\n",
    "    eigenvalues, eigenvectors = eig[0], eig[1]\n",
    "\n",
    "    # create sorted eigenvalue, eigenvector pairs\n",
    "    eigenpairs = []\n",
    "    for i in np.arange(len(eigenvalues)):\n",
    "        eigenpairs.append((eigenvalues[i], eigenvectors[:,i]))\n",
    "    \n",
    "    # keep the eigenvector corresponding to the second smallest eigenvalue\n",
    "    \n",
    "    #return eigenpairs\n",
    "    second_smallest_eigenvector = np.array(sorted(eigenpairs, key = lambda x: x[0])[1][1])\n",
    "    \n",
    "    # Step 4: Create a vector sigma whose sorted value index i corresponds to node i\n",
    "    # -----------------------------------------\n",
    "    sigma = D@second_smallest_eigenvector\n",
    "\n",
    "    # Step 5: Linear sweep for motif conductance minimization\n",
    "    # obtain the sorted indices of sigma where the ith index represents node i\n",
    "    sorted_sigma = sorted(list(zip(sigma, np.arange(1, len(sigma)+1))))\n",
    "\n",
    "    # obtain the proper orderings of the row and columns\n",
    "    order = np.array([x[1] for x in sorted_sigma]) - 1\n",
    "\n",
    "    # reorder the rows and columns of the adjacency matrix\n",
    "    C = adj_matrix[order]\n",
    "    C = C[:, order]\n",
    "\n",
    "    # obtain the sum of each row\n",
    "    row_sums = np.sum(C, 1)\n",
    "\n",
    "    # calculate the volume of all clusters at each partition\n",
    "    volumes = np.cumsum(row_sums)\n",
    "    volumes_other = np.sum(np.sum(adj_matrix, 0)) * np.ones((len(order))) - volumes\n",
    "\n",
    "    # calculate the conductances at each partition\n",
    "    conductances = np.cumsum(row_sums - 2 * np.sum(np.tril(C), 1)) / np.minimum(volumes, volumes_other)\n",
    "    conductances = np.nan_to_num(conductances, nan = 1)\n",
    "\n",
    "    # find the index of the minimal motif conductance\n",
    "    minimum_index = np.argmin(conductances)\n",
    "    \n",
    "    # partition the cluster which achieves the minimum conductance\n",
    "    optimal_cluster = np.array([x[1] for x in sorted_sigma[:minimum_index + 1]])\n",
    "    return optimal_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-275-a0ea5418f619>:57: RuntimeWarning: invalid value encountered in true_divide\n",
      "  conductances = np.cumsum(row_sums - 2 * np.sum(np.tril(C), 1)) / np.minimum(volumes, volumes_other)\n"
     ]
    }
   ],
   "source": [
    "OLD_M10_optimal = single_cluster(OLD_M10_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([319, 373, 336, 146,  18, 106, 121,  63,  11, 145, 198,  99, 141,\n",
       "       249, 219,   5,  87,  71, 153, 113, 228, 412, 241,  51, 323,  77,\n",
       "       415, 239, 205,  34,  82, 192, 385,  50, 438, 125, 424, 325,  22,\n",
       "        95, 278, 215, 102, 439,   6, 226,  84, 254, 238,  55, 235,   3,\n",
       "       223, 111, 123, 310, 377, 417,  85, 270, 158, 351, 220, 408,  76,\n",
       "       201, 397, 311, 418, 164,  92, 288, 191, 407,  36, 208, 151,   7,\n",
       "       331, 332, 165, 139, 202, 176, 117, 152, 276, 299, 360, 229, 272,\n",
       "       428, 101,  60, 372, 135, 414, 359, 347,  78, 184, 324, 342, 368,\n",
       "       337,  88, 395, 316, 289, 437, 433, 199, 195,  89, 390, 409,  74,\n",
       "       133,  73, 329, 262, 108, 300, 116, 250,  14,  68, 284, 273,  28,\n",
       "       394, 252,  86, 154, 148, 356, 222, 306, 149, 403, 296, 406,  54,\n",
       "       376, 138, 304, 242, 341, 253,   1, 405, 328, 315, 298, 348,  97,\n",
       "       308, 147, 258, 297, 231, 224, 178, 109, 429, 427, 277, 173, 114,\n",
       "       357, 132, 322, 265, 268, 434, 419, 392, 321, 396, 378, 248, 225,\n",
       "       292, 251, 119, 203,  24,   9, 364, 155, 312,  67, 425, 257,  27,\n",
       "       160,  19, 169, 358,  49, 120, 293, 105, 431, 327, 382, 214,  57,\n",
       "        61])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_M10_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[0,3,1,1,1,0,0,0,0,0], \n",
    "              [3,0,1,1,1,1,1,0,0,0],\n",
    "              [1,1,0,0,0,0,0,0,0,0],\n",
    "              [1,1,0,0,0,0,0,0,0,0],\n",
    "              [1,1,0,0,0,0,0,0,0,0],\n",
    "              [0,1,0,0,0,0,1,1,1,0],\n",
    "              [0,1,0,0,0,1,0,0,0,0],\n",
    "              [0,0,0,0,0,1,0,0,2,1],\n",
    "              [0,0,0,0,0,1,0,2,0,1],\n",
    "              [0,0,0,0,0,0,0,1,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-251-31a5165a1bd4>:57: RuntimeWarning: invalid value encountered in true_divide\n",
      "  conductances = np.cumsum(row_sums - 2 * np.sum(np.tril(C), 1)) / np.minimum(volumes, volumes_other)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 5, 1, 3, 2])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cluster(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
